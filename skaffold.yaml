# Skaffold is going to make it easy to get our different microservices up and running (and maintained) inside of our k8s cluster.
apiVersion: skaffold/v2alpha3
kind: Config
# Deploy section is going to list out all the different config files we want to load into our cluster.
deploy:
  kubectl:
    # The manifest line tells skaffold to watch our k8s directory for changes in any of the files.
    # Upon any change, it shall reapply the respective yaml config files to our cluster. Essentially, skaffold is doing three things:
    # 1, upon starting skaffold, it's going to apply all config files listed in the manifests,
    # 2, upon us making changes to the config files listed in the manifests, it's going to re-apply them,
    # 3, upon us stopping skaffold, it's going to delete all objects related to the config files listed in the manifests.
    # (3 is good because our local machine is ONE k8s cluster, and we want to keep it clean for instance when we work on several different projects.)
    manifests:
      - ./infra/k8s/*
build:
  # # We can only specify either local or remote builds. As we're using GCP, the former local one is commented out.
  # local:
  #   # Disable default behavior of pushing updated images to Dockerhub, as not needed when we work with Skaffold
  #   push: false
  # In case we use a cluster on GCP, we need to specify the following:
  googleCloudBuild:
    projectId: ticketing-dev-udemy-289609
  # Artifacts section tells Skaffold about something inside of our project that it needs to maintain. Essentially, we're saying, e.g. there is
  # going to be a pod that is running code out of our /auth directory (`context`). Whenever something changes inside that directory, Skaffold is going to
  # try and update our pod, in two ways: manual: if it is a JS file, drop the JS file directly into the pod. If it is a different file, just rebuild
  # the whole image, and update the deployment tied to it. For the manual JS update: note that INSIDE the container contained in the pod, we have
  # the create-react-app dev server (if applicable) and the nodemon utility. Both will, for changes INSIDE the container, restart the respective servers.
  # So, there's two levels of updates monitoring ongoing: Skaffold for stuff within the code base, and CRA dev server / nodemon WITHIN a container in a
  # pod that make sure that servers / primary processes are restarted upon manual changes.
  artifacts:
    # If we use a cluster on GCP, we need to use the image name that GCP will assign to our images, which is structured as follows:
    # (the last part is the name of our project directory) (before GCP, locally, we just used `busdav/auth`)
    - image: us.gcr.io/ticketing-dev-udemy-289609/auth
      context: auth
      docker:
        dockerfile: Dockerfile
      sync:
        # Skaffold can monitor "synced" and "unsynced" files.
        # Synced: = listed in the "synced" section of the skaffold config file. is usually what we have in our src directory - we tell skaffold,
        # "any changes to those files, just sync it to the respective pod". Means, no rebuild - just take the update file and stick it
        # directly into the updated pod.
        # Unsynced: = not listed in the "synced" section of the skaffold config file. These are the files where we want the Docker image to be rebuilt
        # upon changes (e.g. package.json). If we're using a VM on GCP rather than our local machine, skaffold is going to upload all of our src code
        # to Google Cloud Build, along with Dockerfile, will run Docker Builder, get an updated image, and will then tell the Deployments on the
        # relevant Node we've created on our VM on GCP, that there is a new image available. The Deployment will then restart all of its pods
        # using the updated, latest image.
        manual:
          # src: the set of files that skaffold needs to watch. We want skaffold to watch, inside of our src directory, ALL the files that end with '.ts'.
          # (see above for more info)
          - src: "src/**/*.ts"
            # Destination: where to sync this file to inside of our running containter. The '.' means essentially means 'just take wherever this file was
            # found from, and through it into the corresponding path inside the container'.
            dest: .
    - image: us.gcr.io/ticketing-dev-udemy-289609/client
      context: client
      docker:
        dockerfile: Dockerfile
      sync:
        manual:
          - src: "**/*.js"
            dest: .
